%!TEX root = brainreader.tex

\section{Methods}

Our processing pipeline takes as input two pieces of data for each second:

\begin{itemize}
\item The top 100 guesses (based on fMRI data) - each guess has 15 frames
\item The log-likelihood (LLH) of each guess
\end{itemize}

We first forcibly align clips using pyramid-based HOG.  We then extract SIFT features from the beginning and ending of each of the top guesses and calculate SIFT flow between them.  Using cost back-propagation, we find the lowest-cost path through the remaining clips.  Finally, we perform morphing between these clips using SIFT keypoints and output the final clip compilations.

Clips (both original and guessed) are 1 second in length, and have 15 frames per second.  We do not have data on whether there are scene breaks within a 1 second clip.  

\subsection{Alignment - HOG Features}

Histogram of Oriented Gradients (HOG) features roughly indicate edges in an image as well as the orientation of those edges.  We use HOG features to ensure good spatial alignment of guess footage, which results in a nicer-looking average appearance.

We calculate the HOG features of the highest-ranked clip, then, using gaussian pyramids, we shift all other guess clips around to minimize the SSD between their HOG features and those of the highest-ranked clip.  This process is physically based in the fMRI data, as the visual processing centers of the brain react in specific ways to edges presented in particular orientations and in particular locations across the visual field.  Thus we see this ``pruning'' step as non-essential, as we would expect that the fMRI data and subsequent ranking step (performed prior to our getting the data) is already based on these features.

\subsection{Consistency - SIFT Features}

Scale-Invariant Feature Transform (SIFT) features, often used in image recognition tasks, can give higher-level information about the contents of a scene.  We want to minimize the key point flow (i.e., scene composition) between the last frame of one clip and the first frame of the next clip.  SIFT keypoints have been used for nearest-neighbor database searches (e.g., in the SIFT flow paper), and can successfully extract, for example, a street image to match a street image, even when the \emph{optical} flow between the two street images is large.  We use this to keep a thematically consistent scene across timesteps.

We use SIFT flow to calculate costs for transitioning between one clip and the next.  We simply calculate the SIFT flow between the last frame of one clip and the first frame of all potential next clips.  We then use cost back-propagation, i.e., dynamic programming, to find the lowest semantic cost path through all the clips remaining after HOG pruning.

\subsection{Visuals - Image morphing}

To make our output visuals more consistent, we introduce an aspect of warping between the final selected clips.  This warping is intended to preserve object motion and position across clip boundaries: for example, a person walking in one clip should not jump to a new location in the next clip, and she should not drastically change in appearance at the clip boundary.  In addition, we are also confined to the space of clips already selected, and we do not add any new or extended clips to improve overlap information.

This step also uses SIFT flow.  We c