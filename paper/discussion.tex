%!TEX root = brainreader.tex

\section{Discussion}

As our understanding of the brain becomes more and more precise, this type of visualization will surely get better.  This iteration of the BrainDreamer project lacks information about colors and semantics: addition of both would certainly lead to even more accurate results.

Additionally, some results in our dataset are certainly more convincing than others.  Data for which there are many nearly-precise matchings in the database (for example, of human faces) lead to much nicer visualizations, while more unusual data (for example, nudibranchs and other sea creatures) must have their edges ``re-constituted'' by many near matches overlaid.  This is a limitation of the dataset itself. The database of 18,000,000 seconds of clips is quite diverse, but is still limited. While our alignment and visualization techniques can help, some images in the movie that the people saw cannot be well-matched. Additionally, the decoding is based on fMRI responses in the visual cortex and on a model that captures low-level visual information. Some movie information may be better represented in the brain according to its narrative content and higher-level processing. Thus, some images in the movie may not be well reconstructed due to the limitations of the model.

In future work, it would be beneficial to quantitatively compare our visualization techniques with the decoded fMRI data: for example by measuring distances between presented edges and edges in the final visualization, or by presenting the visualization to subjects to compare the brain's reaction to it with the brain's reaction to the original stimulus.